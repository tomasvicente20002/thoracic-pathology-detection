{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beddb9b1",
   "metadata": {},
   "source": [
    "# Conversão de Anotações para Formato YOLO\n",
    "Este notebook carrega os ficheiros `train.json` e `test.json`, converte as anotações de caixas delimitadoras para o formato YOLO, copia as imagens e gera os ficheiros `.txt` correspondentes com as labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0cad0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\lynxv\\anaconda3\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lynxv\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\lynxv\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f97c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# Diretórios\n",
    "TRAIN_JSON_PATH = 'train.json'\n",
    "TEST_JSON_PATH = 'test.json'\n",
    "TRAIN_IMG_DIR = 'train_data'\n",
    "TEST_IMG_DIR = 'test_data'\n",
    "OUTPUT_DIR = 'chestx_det10_yolo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f5e43",
   "metadata": {},
   "source": [
    "## Carregar Anotações\n",
    "Abrimos os ficheiros `train.json` e `test.json` que contêm as anotações no formato original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d7d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carregar dados JSON\n",
    "with open(TRAIN_JSON_PATH, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "with open(TEST_JSON_PATH, 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362d6937",
   "metadata": {},
   "source": [
    "## Obter Classes Únicas\n",
    "Extraímos todas as classes únicas presentes no conjunto de dados e mapeamo-las para IDs numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6112f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Obter todas as classes únicas\n",
    "all_classes = set()\n",
    "for item in train_data + test_data:\n",
    "    all_classes.update(item['syms'])\n",
    "all_classes = sorted(list(all_classes))\n",
    "class_to_id = {cls: idx for idx, cls in enumerate(all_classes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1989840d",
   "metadata": {},
   "source": [
    "## Conversão para Formato YOLO\n",
    "\n",
    "O modelo YOLO (You Only Look Once) espera que as **bounding boxes** estejam no **formato normalizado**, ou seja, todos os valores são representados entre 0 e 1, relativos ao tamanho da imagem.\n",
    "\n",
    "A função `convert_to_yolo` transforma as caixas de coordenadas absolutas `[x_min, y_min, x_max, y_max]` — que representam os cantos superior esquerdo e inferior direito da caixa — para o formato esperado por YOLO: `[x_center, y_center, width, height]`.\n",
    "\n",
    "---\n",
    "\n",
    "### Fórmulas de Conversão\n",
    "\n",
    "Dado:\n",
    "- `w`: largura da imagem\n",
    "- `h`: altura da imagem\n",
    "- `x_min, y_min, x_max, y_max`: coordenadas absolutas da caixa\n",
    "\n",
    "Calculamos:\n",
    "\n",
    "$$\n",
    "x_{center} = \\frac{x_{min} + x_{max}}{2 \\cdot w}\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_{center} = \\frac{y_{min} + y_{max}}{2 \\cdot h}\n",
    "$$\n",
    "\n",
    "$$\n",
    "width = \\frac{x_{max} - x_{min}}{w}\n",
    "$$\n",
    "\n",
    "$$\n",
    "height = \\frac{y_{max} - y_{min}}{h}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Formato Final por Linha (em ficheiros `.txt`)\n",
    "\n",
    "O formato geral é:\n",
    "\n",
    "```\n",
    "<class_id> <x_center> <y_center> <width> <height>\n",
    "```\n",
    "\n",
    "- **`class_id = 2`**  \n",
    "  → Índice da classe da anomalia (ex.: se `names[2] = 'Nodule'`, então representa um nódulo).\n",
    "\n",
    "- **`x_center = 0.3`**  \n",
    "  → O centro da caixa está a **30% da largura da imagem**.\n",
    "\n",
    "- **`y_center = 0.4`**  \n",
    "  → O centro da caixa está a **40% da altura da imagem**.\n",
    "\n",
    "- **`width = 0.2`**  \n",
    "  → A largura da caixa ocupa **20% da largura da imagem**.\n",
    "\n",
    "- **`height = 0.2`**  \n",
    "  → A altura da caixa ocupa **20% da altura da imagem**.\n",
    "\n",
    "---\n",
    "\n",
    "### Exemplo prático com imagem de 1000×1000\n",
    "\n",
    "Se a imagem tem 1000 pixels de largura e 1000 pixels de altura:\n",
    "\n",
    "- `x_center = 0.3 × 1000 = 300 px`\n",
    "- `y_center = 0.4 × 1000 = 400 px`\n",
    "- `width = 0.2 × 1000 = 200 px`\n",
    "- `height = 0.2 × 1000 = 200 px`\n",
    "\n",
    "Portanto, a caixa irá de:\n",
    "\n",
    "- `x = 300 - 100 = 200` até `x = 300 + 100 = 400`\n",
    "- `y = 400 - 100 = 300` até `y = 400 + 100 = 500`\n",
    "\n",
    "---\n",
    "\n",
    "### Vantagens da Normalização\n",
    "\n",
    "- Permite treinar modelos em imagens de diferentes tamanhos.\n",
    "- Evita depender da resolução original na inferência.\n",
    "- É mais leve e eficiente para deteção em tempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d68889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Função para converter boxes para formato YOLO\n",
    "def convert_to_yolo(box, img_w, img_h):\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    x_center = (x_min + x_max) / 2 / img_w\n",
    "    y_center = (y_min + y_max) / 2 / img_h\n",
    "    width = (x_max - x_min) / img_w\n",
    "    height = (y_max - y_min) / img_h\n",
    "    return x_center, y_center, width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f337df",
   "metadata": {},
   "source": [
    "## Processar Conjuntos de Dados\n",
    "Esta função converte anotações, cria diretórios, copia imagens e salva as labels no formato YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e33b2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Função para processar imagens e labels\n",
    "def process_dataset(data, image_dir, subset):\n",
    "    image_out_dir = os.path.join(OUTPUT_DIR, 'images', subset)\n",
    "    label_out_dir = os.path.join(OUTPUT_DIR, 'labels', subset)\n",
    "    os.makedirs(image_out_dir, exist_ok=True)\n",
    "    os.makedirs(label_out_dir, exist_ok=True)\n",
    "\n",
    "    for item in tqdm(data, desc=f'Processing {subset}'):\n",
    "        img_name = item['file_name']\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        label_path = os.path.join(label_out_dir, img_name.replace('.png', '.txt'))\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Imagem não encontrada: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img_w, img_h = img.size\n",
    "        except:\n",
    "            continue  # ignorar imagens que não abrem\n",
    "\n",
    "        lines = []\n",
    "        for cls, box in zip(item['syms'], item['boxes']):\n",
    "            cls_id = class_to_id[cls]\n",
    "            x_center, y_center, width, height = convert_to_yolo(box, img_w, img_h)\n",
    "            lines.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write('\\n'.join(lines))\n",
    "\n",
    "        # copiar imagem\n",
    "        dst_img_path = os.path.join(image_out_dir, img_name)\n",
    "        try:\n",
    "            shutil.copyfile(img_path, dst_img_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao copiar {img_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9165dce",
   "metadata": {},
   "source": [
    "## Aplicar Conversão aos Dados\n",
    "Chamamos a função para converter e copiar as imagens de treino e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce72b257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train:   0%|          | 0/3001 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 3001/3001 [00:52<00:00, 57.62it/s]\n",
      "Processing val: 100%|██████████| 542/542 [00:09<00:00, 58.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# 5. Processar treino e teste\n",
    "process_dataset(train_data, TRAIN_IMG_DIR, 'train')\n",
    "process_dataset(test_data, TEST_IMG_DIR, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04818ae2",
   "metadata": {},
   "source": [
    "## Gerar Ficheiro `data.yaml`\n",
    "O ficheiro `data.yaml` é necessário para treinar com YOLOv8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1768c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Criar ficheiro data.yaml\n",
    "yaml_path = os.path.join(OUTPUT_DIR, 'data.yaml')\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(f\"path: {OUTPUT_DIR}\\n\")\n",
    "    f.write(\"train: images/train\\n\")\n",
    "    f.write(\"val: images/val\\n\")\n",
    "    f.write(f\"nc: {len(all_classes)}\\n\")\n",
    "    f.write(f\"names: {all_classes}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
